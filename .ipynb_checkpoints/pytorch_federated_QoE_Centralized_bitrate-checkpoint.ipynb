{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb881815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch mlp for regression\n",
    "from numpy import vstack\n",
    "from numpy import sqrt\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import MSELoss\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from sklearn import preprocessing\n",
    "from torch import nn\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aea77583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset definition\n",
    "class CSVDataset(Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self, path):\n",
    "        # load the csv file as a dataframe\n",
    "        df = read_csv(path, header=None)\n",
    "        \n",
    "        df.rename(columns=df.iloc[0]).drop(df.index[0])\n",
    "        # store the inputs and outputs\n",
    "        self.X = df.values[1:, 0:16].astype('float32')\n",
    "        self.y = df.values[1:, 16:17].astype('float32')\n",
    "        \n",
    "        self.X = torch.from_numpy(self.X)\n",
    "        self.y = torch.from_numpy(self.y)\n",
    "\n",
    "        # ensure target has the right shape\n",
    "        #self.y = self.y.reshape((len(self.y), 1))\n",
    "\n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    "\n",
    "    # get indexes for train and test rows\n",
    "    def get_splits(self, n_test=0.33):\n",
    "        # determine sizes\n",
    "        test_size = round(n_test * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        # calculate the split\n",
    "        return random_split(self, [train_size, test_size])\n",
    "\n",
    "class MLP(nn.Module):\n",
    "  '''\n",
    "    Multilayer Perceptron for regression.\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Linear(9, 64),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(64, 32),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(32, 1)\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''\n",
    "      Forward pass\n",
    "    '''\n",
    "    return self.layers(x)\n",
    "\n",
    "\n",
    "\n",
    "# prepare the dataset\n",
    "def prepare_data(path):\n",
    "    # load the dataset\n",
    "    dataset = CSVDataset(path)\n",
    "    # calculate split\n",
    "    train, test = dataset.get_splits()\n",
    "    # prepare data loaders\n",
    "    train_dl = DataLoader(train, batch_size=32, shuffle=False)\n",
    "    test_dl = DataLoader(test, batch_size=32, shuffle=False)\n",
    "    return train_dl, test_dl\n",
    "\n",
    "# train the model\n",
    "def train_model(train_dl, model):\n",
    "    # define the optimization\n",
    "    criterion = MSELoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    # enumerate epochs\n",
    "    for epoch in range(300):\n",
    "        # enumerate mini batches\n",
    "        for i, (inputs, targets) in enumerate(train_dl):\n",
    "            # clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # compute the model output\n",
    "            yhat = model(inputs)\n",
    "            # calculate loss\n",
    "            loss = criterion(yhat, targets)\n",
    "            # credit assignment\n",
    "            loss.backward()\n",
    "            # update model weights\n",
    "            optimizer.step()\n",
    "\n",
    "# evaluate the model\n",
    "def evaluate_model(test_dl, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        # evaluate the model on the test set\n",
    "        output = model(inputs)\n",
    "        # retrieve numpy array\n",
    "        output = output.detach().numpy()\n",
    "        actual = targets.numpy()\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        # store\n",
    "        predictions.append(output)\n",
    "        actuals.append(actual)\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "    # calculate mse\n",
    "    mse = mean_squared_error(actuals, predictions)\n",
    "    return mse\n",
    "\n",
    "# make a class prediction for one row of data\n",
    "def predict(row, model):\n",
    "    # convert row to data\n",
    "    row = Tensor([row])\n",
    "    # make prediction\n",
    "    yhat = model(row)\n",
    "    # retrieve numpy array\n",
    "    yhat = yhat.detach().numpy()\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6a3d8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1543, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "path = './data/qoe/federated_devices/pokemon_complet_ABR_BITRATE.csv'\n",
    "df = read_csv(path, header=None)\n",
    "\n",
    "        \n",
    "df.rename(columns=df.iloc[0]).drop(df.index[0])\n",
    "# store the inputs and outputs\n",
    "X = df.values[1:, 0:16].astype('float32')\n",
    "y = df.values[1:, 16:17].astype('float32')\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5466c946",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scale_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/qoe/federated_devices/pokemon_complet_ABR_BITRATE.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m train_dl, test_dl \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_dl\u001b[38;5;241m.\u001b[39mdataset), \u001b[38;5;28mlen\u001b[39m(test_dl\u001b[38;5;241m.\u001b[39mdataset))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# define the network\u001b[39;00m\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mprepare_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_data\u001b[39m(path):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# load the dataset\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCSVDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# calculate split\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mget_splits()\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mCSVDataset.__init__\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m16\u001b[39m:\u001b[38;5;241m17\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my):\n\u001b[1;32m     14\u001b[0m  \u001b[38;5;66;03m# Apply scaling if necessary\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mscale_data\u001b[49m:\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX \u001b[38;5;241m=\u001b[39m StandardScaler()\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scale_data' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "path = './data/qoe/federated_devices/pokemon_complet_ABR_BITRATE.csv'\n",
    "train_dl, test_dl = prepare_data(path)\n",
    "print(len(train_dl.dataset), len(test_dl.dataset))\n",
    "# define the network\n",
    "model = MLP(16)\n",
    "# train the model\n",
    "train_model(train_dl, model)\n",
    "# evaluate the model\n",
    "mse = evaluate_model(test_dl, model)\n",
    "print('MSE: %.3f, RMSE: %.3f' % (mse, sqrt(mse)))\n",
    "#make a single prediction (expect class=1)\n",
    "#row =  [22,1024,0,0.472,0.034,360,736,24,2,869,4,1,0,3,0,26]\n",
    "row =  [38,1536,0.486,0.078,360,912,1,0,2,0,19,3,3,3,3,3]\n",
    "\n",
    "yhat = predict(row, model)\n",
    "print('Predicted:',yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c98defa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "torch.save(model.state_dict(), './model/model_central_training.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5231c815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1543, 1)\n"
     ]
    }
   ],
   "source": [
    "path = './data/qoe/federated_devices/pokemon_complet_ABR_BITRATE.csv'\n",
    "df = read_csv(path, header=None)\n",
    "\n",
    "X = df.values[1:, 0:16].astype('float32')\n",
    "y = df.values[1:, 16:21].astype('float32')\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b81a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
