{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4481e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "import syft as sy\n",
    "from torch import Tensor\n",
    "from syft.frameworks.torch.fl import utils\n",
    "\n",
    "from syft.workers.websocket_client import WebsocketClientWorker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0dcbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def __init__(self):\n",
    "        self.epochs = 100\n",
    "        self.lr = 0.001\n",
    "        self.test_batch_size = 8\n",
    "        self.batch_size = 8\n",
    "        self.log_interval = 10\n",
    "        self.seed = 1\n",
    "    \n",
    "args = Parser()\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e2007",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/qoe/Client1_2.csv'\n",
    "df = read_csv(path, header=None)\n",
    "df.head()\n",
    "\n",
    "train_set=df.sample(frac=0.8,random_state=200) #random state is a seed value\n",
    "test_set=df.drop(train_set.index)\n",
    "\n",
    "x  = train_set.iloc[: , :-1]\n",
    "y = train_set.iloc[: , -1]\n",
    "\n",
    "x_test  = test_set.iloc[: , :-1]\n",
    "y_test = test_set.iloc[: , -1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf47143",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/qoe/Client2_2.csv'\n",
    "df2 = read_csv(path, header=None)\n",
    "df2.head()\n",
    "\n",
    "train_set2=df2.sample(frac=0.8,random_state=200) #random state is a seed value\n",
    "test_set2=df2.drop(train_set.index)\n",
    "\n",
    "x2  = train_set2.iloc[: , :-1]\n",
    "y2 = train_set2.iloc[: , -1]\n",
    "\n",
    "x_test2  = test_set2.iloc[: , :-1]\n",
    "y_test2 = test_set2.iloc[: , -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d5172",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = torch.from_numpy(x.to_numpy()).float()\n",
    "y = torch.from_numpy(y.to_numpy()).float()\n",
    "x_test = torch.from_numpy(x_test.to_numpy()).float()\n",
    "y_test = torch.from_numpy(y_test.to_numpy()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93495fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = torch.from_numpy(x2.to_numpy()).float()\n",
    "y2 = torch.from_numpy(y2.to_numpy()).float()\n",
    "x_test2 = torch.from_numpy(x_test2.to_numpy()).float()\n",
    "y_test2 = torch.from_numpy(y_test2.to_numpy()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510f8c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean = x.mean(0, keepdim=True)\n",
    "#dev = x.std(0, keepdim=True)\n",
    "#mean[:, 3] = 0.\n",
    "#dev[:, 3] = 1.\n",
    "#x = (x - mean) / dev\n",
    "#x_test = (x_test - mean) / dev\n",
    "\n",
    "train = TensorDataset(x, y)\n",
    "test = TensorDataset(x_test, y_test)\n",
    "train_loader = DataLoader(train, batch_size=args.batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=args.test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d03b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = TensorDataset(x2, y2)\n",
    "test2 = TensorDataset(x_test2, y_test2)\n",
    "train_loader2 = DataLoader(train2, batch_size=args.batch_size, shuffle=True)\n",
    "test_loader2 = DataLoader(test2, batch_size=args.test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c07836",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(13, 32)\n",
    "        self.fc2 = nn.Linear(32, 24)\n",
    "        self.fc4 = nn.Linear(24, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 13)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec6a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "bob_worker = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice_worker = sy.VirtualWorker(hook, id=\"alice\")\n",
    "# kwargs_websocket = {\"host\": \"localhost\", \"hook\": hook}\n",
    "# alice = WebsocketClientWorker(id='alice', port=8779, **kwargs_websocket)\n",
    "# bob = WebsocketClientWorker(id='bob', port=8778, **kwargs_websocket)\n",
    "compute_nodes = [bob_worker,alice_worker]\n",
    "compute_nodes_bob = [bob_worker]\n",
    "compute_nodes_alice = [alice_worker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb0c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_dataset = (list(), list())\n",
    "train_distributed_dataset = []\n",
    "\n",
    "for batch_idx, (data,target) in enumerate(train_loader):\n",
    "    data = data.send(compute_nodes_bob[batch_idx % len(compute_nodes_bob)])\n",
    "    target = target.send(compute_nodes_bob[batch_idx % len(compute_nodes_bob)])\n",
    "    remote_dataset[batch_idx % len(compute_nodes_bob)].append((data, target))\n",
    "    \n",
    "    \n",
    "for batch_idx, (data,target) in enumerate(train_loader2):\n",
    "    data = data.send(compute_nodes_alice[batch_idx % len(compute_nodes_alice)])\n",
    "    target = target.send(compute_nodes_alice[batch_idx % len(compute_nodes_alice)])\n",
    "    remote_dataset[batch_idx % len(compute_nodes_alice)].append((data, target))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc4b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "bobs_model = Net()\n",
    "alices_model = Net()\n",
    "bobs_optimizer = optim.SGD(bobs_model.parameters(), lr=args.lr)\n",
    "alices_optimizer = optim.SGD(alices_model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e64ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [bobs_model, alices_model]\n",
    "optimizers = [bobs_optimizer, alices_optimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5185a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be39f813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(data, target, model, optimizer):\n",
    "    model.send(data.location)\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(data)\n",
    "    loss = F.mse_loss(prediction.view(-1), target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return model\n",
    "\n",
    "def train():\n",
    "    for data_index in range(len(remote_dataset[0])-1):\n",
    "        for remote_index in range(len(compute_nodes)):\n",
    "            data, target = remote_dataset[remote_index][data_index]\n",
    "            models[remote_index] = update(data, target, models[remote_index], optimizers[remote_index])\n",
    "        for model in models:\n",
    "            model.get()\n",
    "        return utils.federated_avg({\n",
    "            \"bob\": models[0],\n",
    "            \"alice\": models[1]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3498c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(federated_model):\n",
    "    federated_model.eval()\n",
    "    test_loss = 0\n",
    "    for data, target in test_loader:\n",
    "        output = federated_model(data)\n",
    "        test_loss += F.mse_loss(output.view(-1), target, reduction='sum').item()\n",
    "        predection = output.data.max(1, keepdim=True)[1]\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e60a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(args.epochs):\n",
    "    start_time = time.time()\n",
    "    print(f\"Epoch Number {epoch + 1}\")\n",
    "    federated_model = train()\n",
    "    model = federated_model\n",
    "    test(federated_model)\n",
    "    total_time = time.time() - start_time\n",
    "    print('Communication time over the network', round(total_time, 2), 's\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29257bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "torch.save(model.state_dict(), './model/master_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d257f7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a class prediction for one row of data\n",
    "def predict(row, model):\n",
    "    # convert row to data\n",
    "    row = Tensor([row])\n",
    "    # make prediction\n",
    "    yhat = model(row)\n",
    "    # retrieve numpy array\n",
    "    yhat = yhat.detach().numpy()\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df618c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#row2 = [34011,50,5699,1035,0,6015,0,30003,30003,0,2903,1544292,4.33]\n",
    "row2 =  [57400,57,6023,1051,0,6128,0,30003,30003,0,2903,1565292,4.33]\n",
    "\n",
    "yhat2 = predict(row2, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f65a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predicted: %.3f' % yhat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a44686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
