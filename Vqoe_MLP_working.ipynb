{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d99f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import logging\n",
    "\n",
    "# import Pysyft to help us to simulate federated leraning\n",
    "import syft as sy\n",
    "\n",
    "# hook PyTorch to PySyft i.e. add extra functionalities to support Federated Learning\n",
    "# and other private AI tools\n",
    "hook = sy.TorchHook(torch) \n",
    "\n",
    "# we create two imaginary schools\n",
    "jack = sy.VirtualWorker(hook, id=\"jack\")\n",
    "joe = sy.VirtualWorker(hook, id=\"joe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0fd71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the args\n",
    "args = {\n",
    "    'use_cuda' : False,\n",
    "    'batch_size' : 8,\n",
    "    'test_batch_size' : 8,\n",
    "    'lr' : 0.01,\n",
    "    'log_interval' : 10,\n",
    "    'epochs' : 10\n",
    "}\n",
    "\n",
    "# check to use GPU or not\n",
    "use_cuda = args['use_cuda'] and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7bafc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch mlp for regression\n",
    "from numpy import vstack\n",
    "from numpy import sqrt\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import MSELoss\n",
    "from torch.nn.init import xavier_uniform_\n",
    "\n",
    "# model definition\n",
    "class MLP(Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        # input to first hidden layer\n",
    "        self.hidden1 = Linear(n_inputs, 32)\n",
    "        xavier_uniform_(self.hidden1.weight)\n",
    "        self.act1 = Sigmoid()\n",
    "        # second hidden layer\n",
    "        self.hidden2 = Linear(32, 24)\n",
    "        xavier_uniform_(self.hidden2.weight)\n",
    "        self.act2 = Sigmoid()\n",
    "        \n",
    "        self.hidden3 = Linear(24, 16)\n",
    "        xavier_uniform_(self.hidden3.weight)\n",
    "        self.act3 = Sigmoid()\n",
    "        # third hidden layer and output\n",
    "        self.hidden4 = Linear(16, 1)\n",
    "        xavier_uniform_(self.hidden4.weight)\n",
    "\n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        # input to first hidden layer\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "         # second hidden layer\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        # third hidden layer and output\n",
    "        X = self.hidden4(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ac2b790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49450</td>\n",
       "      <td>54</td>\n",
       "      <td>3719</td>\n",
       "      <td>1108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3795</td>\n",
       "      <td>0</td>\n",
       "      <td>30013</td>\n",
       "      <td>30013</td>\n",
       "      <td>0</td>\n",
       "      <td>2934</td>\n",
       "      <td>1645944</td>\n",
       "      <td>4.33</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50517</td>\n",
       "      <td>52</td>\n",
       "      <td>5902</td>\n",
       "      <td>1095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5859</td>\n",
       "      <td>0</td>\n",
       "      <td>30006</td>\n",
       "      <td>30006</td>\n",
       "      <td>0</td>\n",
       "      <td>2903</td>\n",
       "      <td>1555356</td>\n",
       "      <td>4.33</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47988</td>\n",
       "      <td>47</td>\n",
       "      <td>5806</td>\n",
       "      <td>1051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5857</td>\n",
       "      <td>0</td>\n",
       "      <td>30006</td>\n",
       "      <td>30006</td>\n",
       "      <td>0</td>\n",
       "      <td>2903</td>\n",
       "      <td>1535444</td>\n",
       "      <td>4.33</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56457</td>\n",
       "      <td>55</td>\n",
       "      <td>5978</td>\n",
       "      <td>1099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5989</td>\n",
       "      <td>0</td>\n",
       "      <td>30003</td>\n",
       "      <td>30003</td>\n",
       "      <td>0</td>\n",
       "      <td>2903</td>\n",
       "      <td>1534092</td>\n",
       "      <td>4.33</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56690</td>\n",
       "      <td>54</td>\n",
       "      <td>5931</td>\n",
       "      <td>1133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5932</td>\n",
       "      <td>0</td>\n",
       "      <td>30005</td>\n",
       "      <td>30005</td>\n",
       "      <td>0</td>\n",
       "      <td>2934</td>\n",
       "      <td>1582192</td>\n",
       "      <td>4.33</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1     2     3    4     5   6      7      8   9     10       11  \\\n",
       "0  49450  54  3719  1108  0.0  3795   0  30013  30013   0  2934  1645944   \n",
       "1  50517  52  5902  1095  0.0  5859   0  30006  30006   0  2903  1555356   \n",
       "2  47988  47  5806  1051  0.0  5857   0  30006  30006   0  2903  1535444   \n",
       "3  56457  55  5978  1099  0.0  5989   0  30003  30003   0  2903  1534092   \n",
       "4  56690  54  5931  1133  0.0  5932   0  30005  30005   0  2934  1582192   \n",
       "\n",
       "     12    13  \n",
       "0  4.33  3.96  \n",
       "1  4.33  3.96  \n",
       "2  4.33  3.98  \n",
       "3  4.33  3.96  \n",
       "4  4.33  3.95  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './data/qoe/Client1_2.csv'\n",
    "df = read_csv(path, header=None)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f90e9e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/qoe/Client2_2.csv'\n",
    "df2 = read_csv(path, header=None)\n",
    "df2.head()\n",
    "\n",
    "train_set_2=df2.sample(frac=0.8,random_state=200) #random state is a seed value\n",
    "test_set_2=df2.drop(train_set_2.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97c6298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_set=df.sample(frac=0.8,random_state=200) #random state is a seed value\n",
    "test_set=df.drop(train_set.index)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "322634e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x  = train_set.iloc[: , :-1]\n",
    "y = train_set.iloc[: , -1]\n",
    "\n",
    "y = y.values.reshape((len(y), 1))\n",
    "    \n",
    "\n",
    "x_test  = test_set.iloc[: , :-1]\n",
    "y_test = test_set.iloc[: , -1]\n",
    "\n",
    "train_set_data = torch.from_numpy(x.to_numpy()).float()\n",
    "target_set_data  = torch.from_numpy(y).float()\n",
    "\n",
    "test_set_data = torch.from_numpy(x_test.to_numpy()).float()\n",
    "target_test_set_data = torch.from_numpy(y_test.to_numpy()).float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce3650e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2  = train_set_2.iloc[: , :-1]\n",
    "y2 = train_set_2.iloc[: , -1]\n",
    "\n",
    "y2 = y2.values.reshape((len(y2), 1))\n",
    "    \n",
    "x_test2  = test_set_2.iloc[: , :-1]\n",
    "y_test2 = test_set_2.iloc[: , -1]\n",
    "\n",
    "train_set_data2 = torch.from_numpy(x2.to_numpy()).float()\n",
    "target_set_data2  = torch.from_numpy(y2).float()\n",
    "\n",
    "test_set_data2 = torch.from_numpy(x_test2.to_numpy()).float()\n",
    "target_test_set_data2 = torch.from_numpy(y_test2.to_numpy()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c34bfb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# determine the supported device\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device\n",
    "\n",
    "# convert a df to tensor to be used in pytorch\n",
    "def df_to_tensor(df):\n",
    "    device = get_device()\n",
    "    return torch.from_numpy(df.values).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c03faab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>21192</td>\n",
       "      <td>69</td>\n",
       "      <td>5416</td>\n",
       "      <td>1400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5545</td>\n",
       "      <td>0</td>\n",
       "      <td>30039</td>\n",
       "      <td>30039</td>\n",
       "      <td>0</td>\n",
       "      <td>2934</td>\n",
       "      <td>1554206</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>41173</td>\n",
       "      <td>63</td>\n",
       "      <td>5811</td>\n",
       "      <td>1115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6055</td>\n",
       "      <td>0</td>\n",
       "      <td>30005</td>\n",
       "      <td>30005</td>\n",
       "      <td>0</td>\n",
       "      <td>2903</td>\n",
       "      <td>1594692</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>29756</td>\n",
       "      <td>22</td>\n",
       "      <td>6199</td>\n",
       "      <td>1017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6380</td>\n",
       "      <td>0</td>\n",
       "      <td>30003</td>\n",
       "      <td>30003</td>\n",
       "      <td>0</td>\n",
       "      <td>2966</td>\n",
       "      <td>1597492</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>26345</td>\n",
       "      <td>38</td>\n",
       "      <td>6242</td>\n",
       "      <td>1275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6217</td>\n",
       "      <td>0</td>\n",
       "      <td>30003</td>\n",
       "      <td>30003</td>\n",
       "      <td>0</td>\n",
       "      <td>2966</td>\n",
       "      <td>1567349</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>20125</td>\n",
       "      <td>72</td>\n",
       "      <td>5910</td>\n",
       "      <td>1830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6054</td>\n",
       "      <td>0</td>\n",
       "      <td>30003</td>\n",
       "      <td>30003</td>\n",
       "      <td>0</td>\n",
       "      <td>2934</td>\n",
       "      <td>1556932</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1     2     3    4     5   6      7      8   9     10       11  \\\n",
       "674  21192  69  5416  1400  0.0  5545   0  30039  30039   0  2934  1554206   \n",
       "233  41173  63  5811  1115  0.0  6055   0  30005  30005   0  2903  1594692   \n",
       "739  29756  22  6199  1017  0.0  6380   0  30003  30003   0  2966  1597492   \n",
       "865  26345  38  6242  1275  0.0  6217   0  30003  30003   0  2966  1567349   \n",
       "523  20125  72  5910  1830  0.0  6054   0  30003  30003   0  2934  1556932   \n",
       "\n",
       "       12  \n",
       "674  4.33  \n",
       "233  4.33  \n",
       "739  4.34  \n",
       "865  4.34  \n",
       "523  4.33  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "897ebc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b76ba7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_df_tensor = df_to_tensor(train_set_data)\n",
    "#y_df_tensor = df_to_tensor(target_set_data)\n",
    "#test_tensor = df_to_tensor(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "149968fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we take the help of PySyft's awesome API to prepare the data for us and\n",
    "# distribute for us across 2 workers ie. two schools\n",
    "# normally we dont have to distribute data, data is already there at the site.\n",
    "# We are doing this just to simulate federated learning.\n",
    "# Below code looks just like torch code with just some minor changes. This is what's nice about PySyft.\n",
    "\n",
    "target_set_data = target_set_data.type(torch.LongTensor)\n",
    "\n",
    "bob_train_dataset = sy.BaseDataset(train_set_data,target_set_data).send(jack) \n",
    "anne_train_dataset = sy.BaseDataset(train_set_data2, target_set_data2).send(joe)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#series_tensor = df_to_tensor(series)\n",
    "#federated_train_loader = sy.FederatedDataLoader(bob_train_dataset, ,batch_size=32, shuffle=False, drop_last=False)\n",
    "\n",
    "\n",
    "\n",
    "#federated_train_loader = sy.FederatedDataLoader(\n",
    "#    df_tensor.federate((jake, john)), batch_size=64, shuffle=True)\n",
    "\n",
    "#test_loader = torch.utils.data.DataLoader(test_tensor, batch_size=32, shuffle=True)\n",
    "federated_train_dataset= sy.FederatedDataset([bob_train_dataset, anne_train_dataset])\n",
    "federated_train_loader = sy.FederatedDataLoader(federated_train_dataset, shuffle=False, batch_size=8)\n",
    "\n",
    "#federated_train_loader = sy.FederatedDataLoader(\n",
    "#    datasets.MNIST('../data', train=True, download=True,\n",
    "                 #  transform=transforms.Compose([\n",
    "#                       transforms.ToTensor(),\n",
    "#                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                   ]))\n",
    "#    .federate((grapevine_high, westside_school)),\n",
    "#    batch_size=args['batch_size'], shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# test data remains with us locally\n",
    "# this is the normal torch code to load test data from MNIST\n",
    "# that we are all familiar with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30650cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FederatedDataset\n",
      "    Distributed accross: jack, joe\n",
      "    Number of datapoints: 1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(federated_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7272c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = next(iter(federated_train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bb490dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Wrapper)>[PointerTensor | me:96924076916 -> jack:49864387510]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4777344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    criterion = MSELoss()\n",
    "    # iterate over federated data\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        # send the model to the remote location \n",
    "        model = model.send(data.location)\n",
    "        optimizer.zero_grad()\n",
    "        # the same torch code that we are use to\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "\n",
    "        # this loss is a ptr to the tensor loss \n",
    "        # at the remote location\n",
    "        #loss = F.nll_loss(output, target)\n",
    "        #loss = F.mse_loss(output.view(-1), target.float())\n",
    "        loss = criterion(output, target.float())\n",
    "\n",
    "        # call backward() on the loss ptr,\n",
    "        # that will send the command to call\n",
    "        # backward on the actual loss tensor\n",
    "        # present on the remote machine\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # get back the updated model\n",
    "        model.get()\n",
    "\n",
    "        if batch_idx % args['log_interval'] == 0:\n",
    "\n",
    "            # a thing to note is the variable loss was\n",
    "            # also created at remote worker, so we need to\n",
    "            # explicitly get it back\n",
    "            loss = loss.get()\n",
    "\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, \n",
    "                    batch_idx * args['batch_size'], # no of images done\n",
    "                    len(train_loader) * args['batch_size'], # total images left\n",
    "                    100. * batch_idx / len(train_loader), \n",
    "                    loss.item()\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdd35b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(data, target, model, optimizer):\n",
    "    model.send(data.location)\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(data)\n",
    "    loss = F.mse_loss(prediction.view(-1), target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecd70d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "def train_model(train_dl, model):\n",
    "    # define the optimization\n",
    "    criterion = MSELoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    # enumerate epochs\n",
    "    for epoch in range(100):\n",
    "        # enumerate mini batches\n",
    "        for i, (inputs, targets) in enumerate(train_dl):\n",
    "            # clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # compute the model output\n",
    "            yhat = model(inputs)\n",
    "            # calculate loss\n",
    "            loss = criterion(yhat, targets)\n",
    "            # credit assignment\n",
    "            loss.backward()\n",
    "            # update model weights\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "209b264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            print(data)\n",
    "            print(target)\n",
    "            output = model(data)\n",
    "            # add losses together\n",
    "            test_loss += F.mse_loss(output, target.float(), reduction='sum').item() \n",
    "\n",
    "            # get the index of the max probability class\n",
    "            pred = output.argmax(dim=1, keepdim=True)  \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aee23dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(13, 32)\n",
    "        self.fc2 = nn.Linear(32, 24)\n",
    "        self.fc4 = nn.Linear(24, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.view(-1, 13)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eccde7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model = Net().to(device)\n",
    "model = MLP(13).to(device)\n",
    "#model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args['lr'])\n",
    "\n",
    "\n",
    "logging.info(\"Starting training !!\")\n",
    "\n",
    "for epoch in range(1, args['epochs'] + 1):\n",
    "        train(args, model, device, federated_train_loader, optimizer, epoch)\n",
    "        #test(model, device, test_loader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af6ea1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset definition\n",
    "class CSVDataset(Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self, path):\n",
    "        # load the csv file as a dataframe\n",
    "        df = read_csv(path, header=None)\n",
    "        # store the inputs and outputs\n",
    "        self.X = df.values[:, :-1].astype('float32')\n",
    "        self.y = df.values[:, -1].astype('float32')\n",
    "    \n",
    "        # ensure target has the right shape\n",
    "        self.y = self.y.reshape((len(self.y), 1))\n",
    "\n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    "\n",
    "    # get indexes for train and test rows\n",
    "    def get_splits(self, n_test=0.33):\n",
    "        # determine sizes\n",
    "        test_size = round(n_test * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        # calculate the split\n",
    "        return random_split(self, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25f958a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prepare the dataset\n",
    "def prepare_data(path):\n",
    "    # load the dataset\n",
    "    dataset = CSVDataset(path)\n",
    "    # calculate split\n",
    "    train, test = dataset.get_splits()\n",
    "    # prepare data loaders\n",
    "    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
    "    return train_dl, test_dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c21cc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938 462\n"
     ]
    }
   ],
   "source": [
    "path = './data/qoe/Client3.csv'\n",
    "df3 = prepare_data(path)\n",
    "train_dl, test_dl = prepare_data(path)\n",
    "print(len(train_dl.dataset), len(test_dl.dataset))\n",
    "\n",
    "#test_loader =torch.utils.data.Dataset(test_dl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f052e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, device, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "307d218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a class prediction for one row of data\n",
    "def predict(row, model):\n",
    "    # convert row to data\n",
    "    row = Tensor([row])\n",
    "    # make prediction\n",
    "    yhat = model(row)\n",
    "    # retrieve numpy array\n",
    "    yhat = yhat.detach().numpy()\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a461ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#row2 = [34011,50,5699,1035,0,6015,0,30003,30003,0,2903,1544292,4.33]\n",
    "row =  [57400,57,6023,1051,0,6128,0,30003,30003,0,2903,1565292,4.33] \n",
    "#= 3.98\n",
    "\n",
    "client = predict(row, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predicted: %.3f' % client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6280860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "def evaluate_model(test_dl, model):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        # evaluate the model on the test set\n",
    "        output = model(inputs)\n",
    "        test_loss += F.mse_loss(output, targets.float(), reduction='sum').item() \n",
    "        # retrieve numpy array\n",
    "        output = output.detach().numpy()\n",
    "        actual = targets.numpy()\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        # store\n",
    "        predictions.append(output)\n",
    "        actuals.append(actual)\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "    \n",
    "    # calculate mse\n",
    "    mse = mean_squared_error(actuals, predictions)\n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af300b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = evaluate_model(test_dl, model)\n",
    "print('MSE: %.3f, RMSE: %.3f' % (mse, sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d37241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a21e7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
